{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675961f5",
   "metadata": {},
   "source": [
    "# Simple implementation of ADMM to solve\n",
    "\n",
    "$\\min_x \\|Ax-b\\|^2 + \\lambda\\|x\\|_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da664e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import optlib.operators as op\n",
    "import optlib.c_grad as cg\n",
    "import importlib\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac38dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two new operators that we need\n",
    "#These conform to our operator convention\n",
    "#Each has a forward and a transpose\n",
    "\n",
    "class ifft_op:\n",
    "    \"\"\" Inverse fft operator. Takes a complex\n",
    "        argument as input and produces a real\n",
    "        output.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward (self,x):\n",
    "        return np.real(np.fft.ifftn(np.fft.ifftshift(x)))\n",
    "    def transpose (self,x):\n",
    "        return np.fft.fftshift(np.fft.fftn(np.real(x)))\n",
    "    \n",
    "class selection_op:\n",
    "    \"\"\" Selection operator. Given a vector as an input it\n",
    "        produces as an output certain components of the vector.\n",
    "        See the __init__ and forward methods for details\n",
    "    \"\"\"\n",
    "    def __init__(self,x_shape,idx):\n",
    "        \"\"\" x_shape is the full shape of the input array for forward\n",
    "            idx is the set of indices from which the components of \n",
    "                x are extracted to make the output \n",
    "            idx is required to be produced by np.r_ (see the use below)\n",
    "            For now x is assumed to be 1-dimensional\n",
    "        \"\"\"\n",
    "        self.x_shape=x_shape\n",
    "        self.idx=idx\n",
    "    def forward(self,x):\n",
    "        return x[self.idx]\n",
    "    def transpose(self,x):\n",
    "        z=np.zeros(self.x_shape)\n",
    "        z[idx]=x\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dde5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(cg) Uncomment this if you are changing the cg module to debug\n",
    "\n",
    "def s_thresh(a,alpha):\n",
    "    \"\"\" Soft thresholding needed for ADMM\n",
    "    \"\"\"\n",
    "    return (np.maximum(abs(a),alpha)-alpha)*a/np.abs(a)\n",
    "def h_thresh(a,alpha):\n",
    "    \"\"\" Hard thresholding needed for ADMM\n",
    "    \"\"\"\n",
    "    return (abs(a)>=alpha)*a\n",
    "def norm(x):\n",
    "    \"\"\" Returns the norm of x. Works for complex x\n",
    "        Eventually to be replaced with the norm in \n",
    "            the cg module\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.sum(np.abs(x)**2))\n",
    "\n",
    "\n",
    "def admm_l2_l1(A,b,x0,l1_wt=1.0,rho=1.0,iter_max=100,eps=1e-2):\n",
    "    \"\"\"ADMM L2 L1 function. Minimizes \\|Ax-b\\|^2 + \\lambda \\|x\\|_1\n",
    "       Input:\n",
    "       A: operator, b as described in the formula above. x0 is the initial value of x\n",
    "       l1_wt: This is lambda (I am not using lambda, because that is a protected\n",
    "                                   word in Python)\n",
    "       rho: Augmented Lagrangian parameter for ADMM\n",
    "       iter_max: maximum number of iterations\n",
    "       eps: stopping criterion (needs to be more sophisticated)\n",
    "       \n",
    "       Returns the minimizing x, and a flag indicated whether iter_max was reached\n",
    "    \"\"\"\n",
    "    #Initialize variables\n",
    "    xk=x0\n",
    "    zk=np.zeros_like(x0)\n",
    "    uk=np.zeros_like(x0)\n",
    "    \n",
    "    #initialize iteration\n",
    "    B=op.scalar_prod_op(rho)\n",
    "    mu=10\n",
    "    rk_1=np.inf\n",
    "    sk_1=np.inf\n",
    "    steps=0\n",
    "\n",
    "    #Iterate till termination\n",
    "    while ((steps<iter_max)&((norm(rk_1)>eps)|(norm(sk_1)>eps))):\n",
    "        xk_1,cg_flag=cg.solve_lin_cg(y,A,xk,B=B,c=rho*(zk-uk),max_iter=2,inner_max_iter=6)\n",
    "        zk_1=s_thresh(xk_1+uk,l1_wt/rho)\n",
    "        uk_1=uk+xk_1-zk_1\n",
    "        rk_1=xk_1-zk_1\n",
    "        sk_1= rho*(zk-zk_1)\n",
    "\n",
    "    #Update variables\n",
    "        xk=xk_1\n",
    "        zk=zk_1\n",
    "        uk=uk_1\n",
    "        steps=steps+1\n",
    "        \n",
    "    #Update rho \n",
    "    #You may comment this out if you are adjusting rho manually\n",
    "        if norm(rk_1)> mu*norm(sk_1):\n",
    "            rho=rho*1.5\n",
    "        elif norm(sk_1)> mu*norm(rk_1):\n",
    "            rho=rho/1.5\n",
    "               \n",
    "    return xk,steps<iter_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c1db23",
   "metadata": {},
   "source": [
    "## Use case starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094cfb64",
   "metadata": {},
   "source": [
    "### Create data, add noise and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "324f2c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c0729ab7f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=128\n",
    "t=np.linspace(0,1,128)\n",
    "x_true=np.sin(20*t+2.7)+0.2*np.cos(60*t)  #The true underlying signal\n",
    "x_data=x_true+0.2*np.random.normal(size=t.size) #Data = true signal + noise\n",
    "idx=np.r_[0:10,35:45,60:70,85:97,100:110]   #The components of x to be sampled\n",
    "S=selection_op(x_true.shape,idx)            #Create the selection operator\n",
    "y=S.forward(x_data)                         #Select the data\n",
    "figure,ax=plt.subplots()\n",
    "ax.plot(t,x_true,label='True signal')\n",
    "ax.plot(t,x_data,label='Noisy Signal')\n",
    "ax.plot(t,S.transpose(y),'r*',label='Sampled Data')\n",
    "ax.legend(shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc1bc1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "F=ifft_op()\n",
    "x_est=np.empty(128,dtype=complex)\n",
    "x_est.real=0.0\n",
    "x_est.imag=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce05d09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c070594910>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=op.composite_op(S,F)\n",
    "x_cg,_=admm_l2_l1(A,y,x_est,l1_wt=4.0,rho=1.0,iter_max=100,eps=1e-2)\n",
    "plt.plot(x_cg.real)\n",
    "plt.plot(x_cg.imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "449c1c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c073bef7c0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_est=F.forward(x_cg)\n",
    "figure,ax=plt.subplots()\n",
    "ax.plot(y_est, 'r-',label='Sig Est.')\n",
    "ax.plot(x_true, 'b-',label='True Sig')\n",
    "ax.legend(shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e75dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
